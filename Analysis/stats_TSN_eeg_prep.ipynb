{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNE 2 R - TSN Study\n",
    "\n",
    "Script to export summary measures in specified time windows, for each sensor/trial/subject, to text (CSV) files for import into R.\n",
    "\n",
    "Summary measures available include:\n",
    "- `mean`: mean amplitude in time window\n",
    "- `aman`: adaptive mean negative amplitude in time window (mean over narrow time range, centred on minimum value in the larger time window)\n",
    "- `amap`: adaptive mean positive amplitude\n",
    "---\n",
    "Copyright (c) 2018 Aaron J Newman, NeuroCognitive Imaging Lab, Dalhousie University\n",
    "\n",
    "This program is free software; you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation; either version 2 of the License, or (at your option) any later version. This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import mkdir\n",
    "import os, sys\n",
    "import csv\n",
    "\n",
    "# supress MNE's verbosity:\n",
    "mne.set_log_level('error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all subjects; not separated by group\n",
    "\n",
    "data_path = '..'\n",
    "\n",
    "subjects = [\n",
    "    #'01',\n",
    "    #'02',\n",
    "    #'03',\n",
    "    #'04_pilot'\n",
    "    '04',\n",
    "    '05',\n",
    "    '06',\n",
    "    '07',\n",
    "    '08',\n",
    "    '09',\n",
    "    '10',\n",
    "    '11',\n",
    "    #'12', - This participant's data was very bad and should be excluded\n",
    "    '13',\n",
    "    '14',\n",
    "    '15',\n",
    "    '16',\n",
    "    '17',\n",
    "    '18',\n",
    "    '19',\n",
    "    '20',\n",
    "    '21',\n",
    "    '22',\n",
    "    '23',\n",
    "    '24'\n",
    "]\n",
    "\n",
    "P3_timewin = (0.2, 0.6)\n",
    "LPP_timewin = (0.6, 2)\n",
    "\n",
    "# Define start & end of time window to compute mean amplitude over (depvar:'mean')\n",
    "#   Adaptive mean amplitude (negative) depvar:'aman'\n",
    "#   Adaptive mean amplitude (positive) depvar:'amap'\n",
    "# note that here, we work in milliseconds whereas in other scripts MNE often works in sec\n",
    "# dict of timewins of interest - will get one output file per subject per timewin\n",
    "timewins = {\n",
    "            'P3_mean': {'label':'P3', 'timewin': (200, 600), 'depvar':'mean'},\n",
    "            'P3_peak_pos': {'label':'P3', 'timewin': (200, 600),'depvar':'amap'},\n",
    "            'LPP_mean': {'label':'LPP', 'timewin': (600, 1950), 'depvar':'mean'}, # I don't know why it doesn't work with 2000 - Colin\n",
    "            'LPP_peak_pos': {'label':'LPP', 'timewin': (600, 1950), 'depvar':'aman'}\n",
    "            }\n",
    "ama_width = 30  # width in ms around peak amplitude to compute adaptive mean amplitude\n",
    "\n",
    "scaling_time = 1e3  # re-scale time to milliseconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for computing adaptive mean amplitude\n",
    "\n",
    "Credit for this method of computation goes to Marijn van Vliet\n",
    "\n",
    "https://gist.github.com/wmvanvliet/5cc013ef0f9b18561c74a4d6c1d130b7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_mean(subject, epochs, tw_label, timewin, depvar, ama_width):\n",
    "    epoch_start = timewin[0]\n",
    "    epoch_end   = timewin[1] \n",
    "    # time win in which to find peak; +1 ensures python gets last time point in the series by \n",
    "    search_window = (float(epoch_start)/1000, (float(epoch_end)+1)/1000)  #to float; -Colin\n",
    "\n",
    "    ind_start, ind_stop = np.searchsorted(epochs.times, search_window)\n",
    "\n",
    "    #having trouble here. problem seems to be with the epoch_start variable\n",
    "    data_to_search = epochs.get_data()[:, :, ind_start:ind_stop]\n",
    "    \n",
    "    if depvar=='aman':\n",
    "        peaks = data_to_search.argmin(axis=2)\n",
    "    elif depvar=='amap':\n",
    "        peaks = data_to_search.argmax(axis=2)\n",
    "    else: \n",
    "        print('Error: depvar must be aman or amap')\n",
    "\n",
    "    # The indices are currently based on the data_to_search array. Add the index\n",
    "    # of the start of the search window to the peaks to obtain indexes that can be\n",
    "    # used with the original epochs data.\n",
    "    peaks += ind_start\n",
    "\n",
    "    # Centre on peak, ± half of ama_widy, in sec\n",
    "    peak_window = (-ama_width/2/1000, ama_width/2/1000) \n",
    "\n",
    "    # Convert the peak window into an array of sample indices\n",
    "    peak_window = np.arange(int(peak_window[0] * epochs.info['sfreq']),\n",
    "                            int(peak_window[1] * epochs.info['sfreq']+1))\n",
    "\n",
    "    # Use numpy broadcasting to add the peaks to the peak_window. This gives us for\n",
    "    # each epoch and channel, the corresponding time window over which to compute\n",
    "    # the mean.\n",
    "    time_windows = peaks[:, :, np.newaxis] + peak_window[np.newaxis, np.newaxis, :]\n",
    "    time_windows.shape\n",
    "    \n",
    "    # Use advanced integer indexing to get the corresponding data from the epochs\n",
    "    n_epochs, n_channels, n_samples = epochs.get_data().shape\n",
    "    peak_data = epochs.get_data()[\n",
    "        np.arange(n_epochs)[:, np.newaxis, np.newaxis],  # All epochs\n",
    "        np.arange(n_channels)[np.newaxis, :, np.newaxis],  # All channels\n",
    "        time_windows  # Only the requested time windows\n",
    "    ]\n",
    "    \n",
    "    means = peak_data.mean(axis=2)\n",
    "    # convert MNE's default scaling (V) to microvolts\n",
    "    means = means * 1e6\n",
    "\n",
    "    # get condition labels for each epoch\n",
    "    id_swapped = dict((v, k) for k, v in epochs.event_id.items())\n",
    "    conditions = [id_swapped[k] for k in epochs.events[:, 2]]\n",
    "\n",
    "    # number the epochs\n",
    "    # use normal 1,... indexing for output rather than python's 0,...\n",
    "    epoch_nums = np.arange(1, np.shape(epochs.events)[0]+1)\n",
    "\n",
    "    # converting to DataFrame allows easy insertion of epoch numbers and condition labels, then CSV output\n",
    "    df = pd.DataFrame(data=means, columns=epochs.ch_names, index=[epoch_nums, conditions])\n",
    "    # Write to CSV\n",
    "    out_fname = out_path + subject + '_' + tw_label + '_' + str(epoch_start) + '-' + str(epoch_end) + '.csv'\n",
    "    df.to_csv(out_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the work, looping through subjects. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subjects:\n",
    "    # Make output directory\n",
    "    out_path = './R-data/'\n",
    "    if not os.path.exists(out_path):\n",
    "        os.makedirs(out_path)\n",
    "\n",
    "    # Read in the epoched, cleaned data    \n",
    "    epochs_fname = data_path + '/Data/' + subject + '/' + subject + '-epo.fif'\n",
    "    epochs = mne.read_epochs(epochs_fname, verbose=None)   \n",
    "    \n",
    "    # loop through each timewindow/component of interest, creating mean amplitudes then writing out\n",
    "    for tw in timewins.keys():\n",
    "\n",
    "        if timewins[tw]['depvar']=='mean':\n",
    "            epoch_start = timewins[tw]['timewin'][0]\n",
    "            epoch_end   = timewins[tw]['timewin'][1]\n",
    "            time_win = np.arange(epoch_start,epoch_end)\n",
    "\n",
    "            out_fname = out_path + subject + '_' + tw + '_' + str(epoch_start) + '-' + str(epoch_end) + '.csv'\n",
    "\n",
    "            # Create pandas dataFrame from MNE epochs\n",
    "            df = epochs.to_data_frame(index=['epoch', 'time', 'condition'])\n",
    "            #df = epochs.to_data_frame(scaling_time=scaling_time, index=['epoch', 'time', 'condition'])\n",
    "\n",
    "            # Create multiIndex; see http://pandas.pydata.org/pandas-docs/version/0.15.2/advanced.html#advanced-reindexing-and-alignment\n",
    "            idx = pd.IndexSlice\n",
    "\n",
    "            # Get mean ampl over specified time range for each trial, for magnetometers\n",
    "            means = df.loc[idx[:,time_win],:].groupby(['epoch','condition']).mean()\n",
    "\n",
    "            # Write to CSV\n",
    "            means.to_csv(out_fname)\n",
    "            \n",
    "        elif timewins[tw]['depvar']=='aman' or timewins[tw]['depvar']=='amap':\n",
    "            adaptive_mean(subject, epochs, tw, timewins[tw]['timewin'], timewins[tw]['depvar'], ama_width)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
